# Improving State-of-the-Art GAN Video Synthesis
We propose multiple methods for improving state-of-the-art GAN-based video synthesis approaches. We show that GANs using 3D-convolutions for video generation can easily be extended to predicting coherent depth maps alongside RGB frames, but results indicate that this does not improve RGB accuracy if depth is available. We further propose critic-correction, a method for improving videos generated by latent space curve fitting. Additionally, we study the effect of Principal Component Analysis as well as different backprojection methods on the quality of generated videos.

For a list of publications we borrow code from, please see our report at ./Report/ViDGAN.pdf
## Incorporating Depth
### Code
Our code is based on the [FutureGAN](https://github.com/TUM-LMF/FutureGAN) implementation by Aigner and KÃ¶rner and can be found at ./FutureGAN_Depth.
For training, we used Google Colaboratory, the training script is located at FutureGAN_Depth/Training_Depth.ipynb.
### Results
## Latent Space Video Generation
### Code
The Google Colab scripts we used can be found at:
- LSVG/Train_WGAN_GP.ipynb
- LSVG/Pipeline.ipynb
- LSVG/Train_Pnet.ipynb
### Results

